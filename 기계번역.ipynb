{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chw8207/Transformer/blob/main/%EA%B8%B0%EA%B3%84%EB%B2%88%EC%97%AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip tensorflow-text==2.8.0"
      ],
      "metadata": {
        "id": "NGpEOPeW6CVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce5c47d-97fb-4363-b982-65ed432c303e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"tensorflow-text==2.8.0\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "id": "1krKJhb8bXLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dtv9qT0ZbaDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "H6pzGWy0L02h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "from pickle import dump\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "from pickle import load\n",
        "from pickle import dump\n",
        "from collections import Counter\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "import os\n",
        "import numpy as np\n",
        "# import tensorflow_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr_Q_YouY7Nj"
      },
      "source": [
        "### GPU 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE0tDxrPY2pK",
        "outputId": "bf6c870a-5e2a-4b15-e8b6-07005b86bc5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0' :\n",
        "    raise SystemError('GPU device not found')\n",
        "print(f'Found GPU at: {device_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qib4IC7xY350",
        "outputId": "b1d599c8-da9b-48ae-ca8e-191f07df69e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 14374675455204084798\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 40129593344\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 12714923305354788496\n",
            "physical_device_desc: \"device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVsywyrKLljJ"
      },
      "source": [
        "### WMT 데이터셋 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOyZOxrHLpIc"
      },
      "source": [
        "#### 원시 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hjBTmssK9JlB"
      },
      "outputs": [],
      "source": [
        "# 파일을 메모리에 로드하는 함수 정의\n",
        "def load_doc(filename) :\n",
        "  # 읽기 전용으로 파일 열기\n",
        "  file = open(filename, mode='rt', encoding='utf-8')\n",
        "  # 모든 텍스트 읽기\n",
        "  text = file.read()\n",
        "  # 파일 닫기\n",
        "  file.close()\n",
        "  return text\n",
        "\n",
        "# 로드된 문서는 문장들로 분할됨\n",
        "def to_sentences(doc) :\n",
        "  return doc.strip().split('\\n')\n",
        "\n",
        "# 가장 짧은/가장 긴 문장의 길이 찾기\n",
        "def sentence_lengths(sentences) :\n",
        "  lengths = [len(s.split()) for s in sentences]\n",
        "  return min(lengths), max(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0p2fmTXANCji"
      },
      "outputs": [],
      "source": [
        "# 불러온 문장 라인 정리(노이즈 제거)\n",
        "def clean_lines(lines) :\n",
        "  cleaned = list()\n",
        "  # char filtering을 위해 regex 준비하기\n",
        "  re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "  # 구두점 제거하기 위한 번역표 준비하기\n",
        "  table = str.maketrans('','',string.punctuation)\n",
        "  for line in lines :\n",
        "    # 유니코드 characters 정규화\n",
        "    # 비 아스키 문자 제거\n",
        "    # NFD : 엑센트와 같은 결합 마디를 기본 형태의 문자로 분리함.\n",
        "    line = unicodedata.normalize('NFD',line).encode('ascii', 'ignore')\n",
        "    line = line.decode('UTF-8')\n",
        "    # 공백에서 토큰화\n",
        "    line = line.split()\n",
        "    # 소문자로 변환\n",
        "    line = [word.lower() for word in line]\n",
        "    # 각 토큰에서 구두점 제거\n",
        "    line = [word.translate(table) for word in line]\n",
        "    # 각 토큰에서 프린트할 수 없는 문자 제거\n",
        "    # 문자 w에서 프린트할 수 없는 문자를 빈문자로 대체함.\n",
        "    line = [re_print.sub('',w) for w in line]\n",
        "    # 숫자가 있는 토큰 제거\n",
        "    line = [word for word in line if word.isalpha]\n",
        "    # 문자열 형태로 저장(공백문자를 사용하여 하나로 연결)\n",
        "    cleaned.append(' '.join(line))\n",
        "\n",
        "  return cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQaqj_s9WPXd",
        "outputId": "99dcc301-1054-4d4d-c47f-00a2f03fd666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English data: sentences=2051014, min=1, max=668\n"
          ]
        }
      ],
      "source": [
        "# 영어 데이터 로드하기\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/Transformer/data/Europarl.en-fr.en'\n",
        "doc = load_doc(filename)\n",
        "sentences = to_sentences(doc)\n",
        "minlen, maxlen = sentence_lengths(sentences)\n",
        "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
        "cleanf = clean_lines(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlExX5kzYlek",
        "outputId": "a56f0c29-c647-465b-ffdc-5d230d07ce0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English.pkl  saved\n"
          ]
        }
      ],
      "source": [
        "# pickle이 English.pkl이라는 직렬화된 파일에 덤프한다.\n",
        "filename = 'English.pkl'\n",
        "outfile = open(filename,'wb')\n",
        "pickle.dump(cleanf, outfile)\n",
        "outfile.close()\n",
        "print(filename, ' saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_ieFh_-aFDh",
        "outputId": "d0f730bc-63b1-45f1-c420-56c3e5bd4ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English data: sentences=2051014, min=1, max=693\n"
          ]
        }
      ],
      "source": [
        "# 프랑스어 데이터 로드하기\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/Transformer/data/Europarl.en-fr.fr'\n",
        "doc = load_doc(filename)\n",
        "sentences = to_sentences(doc)\n",
        "minlen, maxlen = sentence_lengths(sentences)\n",
        "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
        "cleanf = clean_lines(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13oIfx37aV58",
        "outputId": "0f3707c6-5092-4fb9-9659-58527e14c0dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French.pkl  saved\n"
          ]
        }
      ],
      "source": [
        "# pickle이 English.pkl이라는 직렬화된 파일에 덤프한다.\n",
        "filename = 'French.pkl'\n",
        "outfile = open(filename,'wb')\n",
        "pickle.dump(cleanf, outfile)\n",
        "outfile.close()\n",
        "print(filename, ' saved')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L7GfTrgavnr"
      },
      "source": [
        "#### 데이터셋 전처리 마무리\n",
        "- 섹션에서 정리된 데이터셋을 로드한 후 마무리된 전처리를 저장하는 함수 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3jvrIDhiavfG"
      },
      "outputs": [],
      "source": [
        "# clean 데이터셋 로드히기\n",
        "def load_clean_sentences(filename) :\n",
        "  return load(open(filename, 'rb'))\n",
        "\n",
        "# clean 문장의 리스트를 파일로 저장하기\n",
        "def save_clean_sentences(sentences, filename) :\n",
        "  dump(sentences, open(filename, 'wb'))\n",
        "  print('Saved: %s' % filename)\n",
        "\n",
        "# 모든 단어에 대한 빈도표 생성하기\n",
        "def to_vocab(lines) :\n",
        "  vocab = Counter()\n",
        "  for line in lines :\n",
        "    tokens = line.split()\n",
        "    vocab.update(tokens)\n",
        "  return vocab\n",
        "\n",
        "# 어휘 카운터는 빈도가 min_occurance 미만인 단어를 검출함\n",
        "def trim_vocb(vocab, min_occurance) :\n",
        "  tokens = [k for k,c in vocab.items() if c >= min_occurance]\n",
        "  return set(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aEx99IXdwHo3"
      },
      "outputs": [],
      "source": [
        "# OOV 단어를 unk(알 수 없는) 토큰으로 대체\n",
        "def update_dataset(lines, vocab) :\n",
        "  new_lines = list()\n",
        "  for line in lines :\n",
        "    new_tokens = list()\n",
        "    for token in line.split() :\n",
        "      if token in vocab :\n",
        "        new_tokens.append(token)\n",
        "      else :\n",
        "        new_tokens.append('unk')\n",
        "    new_line = ' '.join(new_tokens)\n",
        "    new_lines.append(new_line)\n",
        "  return new_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S8DN5f8xNMC",
        "outputId": "84d3a719-246e-44a7-b4ed-15799a801048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocabulary: 133407\n",
            "New English Vocabulary: 44574\n",
            "Saved: english_vocab.pkl\n",
            "line 0 : resumption of the session\n",
            "line 1 : i declare resumed the session of the european parliament adjourned on friday 17 december 1999 and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period\n",
            "line 2 : although as you will have seen the dreaded millennium bug failed to materialise still the people in a number of countries suffered a series of natural disasters that truly were dreadful\n",
            "line 3 : you have requested a debate on this subject in the course of the next few days during this partsession\n",
            "line 4 : in the meantime i should like to observe a minute s silence as a number of members have requested on behalf of all the victims concerned particularly those of the terrible storms in the various countries of the european union\n",
            "line 5 : please rise then for this minute s silence\n",
            "line 6 : the house rose and observed a minute s silence\n",
            "line 7 : madam president on a point of order\n",
            "line 8 : you will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka\n",
            "line 9 : one of the people assassinated very recently in sri lanka was mr unk unk who had visited the european parliament just a few months ago\n",
            "line 10 : would it be appropriate for you madam president to write a letter to the sri lankan president expressing parliaments regret at his and the other violent deaths in sri lanka and urging her to do everything she possibly can to seek a peaceful reconciliation to a very difficult situation\n",
            "line 11 : yes mr evans i feel an initiative of the type you have just suggested would be entirely appropriate\n",
            "line 12 : if the house agrees i shall do as mr evans has suggested\n",
            "line 13 : madam president on a point of order\n",
            "line 14 : i would like your advice about rule 143 concerning inadmissibility\n",
            "line 15 : my question relates to something that will come up on thursday and which i will then raise again\n",
            "line 16 : the cunha report on multiannual guidance programmes comes before parliament on thursday and contains a proposal in paragraph 6 that a form of quota penalties should be introduced for countries which fail to meet their fleet reduction targets annually\n",
            "line 17 : it says that this should be done despite the principle of relative stability\n",
            "line 18 : i believe that the principle of relative stability is a fundamental legal principle of the common fisheries policy and a proposal to subvert it would be legally inadmissible\n",
            "line 19 : i want to know whether one can raise an objection of that kind to what is merely a report not a legislative proposal and whether that is something i can competently do on thursday\n"
          ]
        }
      ],
      "source": [
        "# 영어 데이터셋\n",
        "filename = 'English.pkl'\n",
        "lines = load_clean_sentences(filename)\n",
        "# 어휘 계산\n",
        "vocab = to_vocab(lines)\n",
        "print('English Vocabulary: %d' % len(vocab))\n",
        "# 어휘 감소\n",
        "vocab = trim_vocb(vocab, 5)\n",
        "print('New English Vocabulary: %d' % len(vocab))\n",
        "# mark out of vocabulary words\n",
        "lines = update_dataset(lines, vocab)\n",
        "# 수정된 데이터셋 저장하기\n",
        "filename = 'english_vocab.pkl'\n",
        "save_clean_sentences(lines, filename)\n",
        "# spot check\n",
        "for i in range(20) :\n",
        "  print('line',i,':',lines[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGDOF6iGyoOm",
        "outputId": "da739750-1a83-4b0d-9a9e-8c3b9491a23b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French Vocabulary: 171009\n",
            "New French Vocabulary: 61764\n",
            "Saved: french_vocab.pkl\n",
            "line 0 : reprise de la session\n",
            "line 1 : je declare reprise la session du parlement europeen qui avait ete interrompue le vendredi 17 decembre dernier et je vous renouvelle tous mes vux en esperant que vous avez passe de bonnes vacances\n",
            "line 2 : comme vous avez pu le constater le grand bogue de lan 2000 ne sest pas produit en revanche les citoyens dun certain nombre de nos pays ont ete victimes de catastrophes naturelles qui ont vraiment ete terribles\n",
            "line 3 : vous avez souhaite un debat a ce sujet dans les prochains jours au cours de cette periode de session\n",
            "line 4 : en attendant je souhaiterais comme un certain nombre de collegues me lont demande que nous observions une minute de silence pour toutes les victimes des tempetes notamment dans les differents pays de lunion europeenne qui ont ete touches\n",
            "line 5 : je vous invite a vous lever pour cette minute de silence\n",
            "line 6 : le parlement debout observe une minute de silence\n",
            "line 7 : madame la presidente cest une motion de procedure\n",
            "line 8 : vous avez probablement appris par la presse et par la television que plusieurs attentats a la bombe et crimes ont ete perpetres au sri lanka\n",
            "line 9 : lune des personnes qui vient detre assassinee au sri lanka est m unk unk qui avait rendu visite au parlement europeen il y a quelques mois a peine\n",
            "line 10 : ne pensezvous pas madame la presidente quil conviendrait decrire une lettre au president du sri lanka pour lui communiquer que le parlement deplore les morts violentes dont celle de m unk et pour linviter instamment a faire tout ce qui est en son pouvoir pour chercher une reconciliation pacifique et mettre un terme a cette situation particulierement difficile\n",
            "line 11 : oui monsieur evans je pense quune initiative dans le sens que vous venez de suggerer serait tout a fait appropriee\n",
            "line 12 : si lassemblee en est daccord je ferai comme m evans la suggere\n",
            "line 13 : madame la presidente cest une motion de procedure\n",
            "line 14 : je voudrais vous demander un conseil au sujet de larticle 143 qui concerne lirrecevabilite\n",
            "line 15 : ma question porte sur un sujet qui est a lordre du jour du jeudi et que je souleverai donc une nouvelle fois\n",
            "line 16 : le paragraphe 6 du rapport cunha sur les programmes dorientation pluriannuels qui sera soumis au parlement ce jeudi propose dintroduire des sanctions applicables aux pays qui ne respectent pas les objectifs annuels de reduction de leur flotte\n",
            "line 17 : il precise que cela devrait etre fait malgre le principe de stabilite relative\n",
            "line 18 : a mon sens le principe de stabilite relative est un principe juridique fondamental de la politique commune de la peche et toute proposition le bouleversant serait juridiquement irrecevable\n",
            "line 19 : je voudrais savoir si lon peut avancer une objection de ce type a ce qui nest quun rapport pas une proposition legislative et si je suis habilite a le faire ce jeudi\n"
          ]
        }
      ],
      "source": [
        "# 프랑스어 데이터셋\n",
        "filename = 'French.pkl'\n",
        "lines = load_clean_sentences(filename)\n",
        "# 어휘 계산\n",
        "vocab = to_vocab(lines)\n",
        "print('French Vocabulary: %d' % len(vocab))\n",
        "# 어휘 감소\n",
        "vocab = trim_vocb(vocab, 5)\n",
        "print('New French Vocabulary: %d' % len(vocab))\n",
        "# mark out of vocabulary words\n",
        "lines = update_dataset(lines, vocab)\n",
        "# 수정된 데이터셋 저장하기\n",
        "filename = 'french_vocab.pkl'\n",
        "save_clean_sentences(lines, filename)\n",
        "# spot check\n",
        "for i in range(20) :\n",
        "  print('line',i,':',lines[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ks9_yUpzZzj"
      },
      "source": [
        "### BLUE에 의한 기계 번역 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 기하적 평가"
      ],
      "metadata": {
        "id": "jvxla8-AeJF9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFINDMFYzZrN",
        "outputId": "d00a6764-14de-479d-d1d3-e0b70c626e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emxample 1 1.0\n"
          ]
        }
      ],
      "source": [
        "# 예시 1\n",
        "reference = [['the', 'cat', 'likes', 'milk'], ['cat', 'likes', 'milk']]\n",
        "candidate = ['the', 'cat', 'likes', 'milk']\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print('Emxample 1', score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_Wdu4dgV4a1",
        "outputId": "363a80dd-a98c-4a90-8c3a-36872f4e677e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emxample 2 1.0\n"
          ]
        }
      ],
      "source": [
        "# 예시 2\n",
        "reference = [['the', 'cat', 'likes', 'milk']]\n",
        "candidate = ['the', 'cat', 'likes', 'milk']\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print('Emxample 2', score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLPDXQL5WRqW",
        "outputId": "fa1d1d88-642e-4e08-dbe0-266a8f2e4ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emxample 3 1.0547686614863434e-154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "# 3-gram 오버랩을 찾고 있는 경우\n",
        "reference = [['the', 'cat', 'likes', 'milk']]\n",
        "candidate = ['the', 'cat', 'enjoys', 'milk']\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print('Emxample 3', score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 스무딩 기법 적용 - chencherry smoothing"
      ],
      "metadata": {
        "id": "9NkUY9MSeKvJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lJNo2dQWk6v",
        "outputId": "ed1c9b64-5e10-4c38-eaa2-ba9b2d3fb786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without smoothing score 0.37188004246466494\n"
          ]
        }
      ],
      "source": [
        "# 예제 4(불어-영어 예제)\n",
        "reference = [['je','vous','invite', 'a', 'vous', 'lever','pour', 'cette', 'minute', 'de', 'silence']]\n",
        "candidate = ['levez','vous','svp','pour', 'cette', 'minute', 'de', 'silence']\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print('without smoothing score', score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가에 개방적 스무딩을 추가하기\n",
        "chencherry = SmoothingFunction()\n",
        "r1 = list('je vous invite a vous lever pour cette minute de silence')\n",
        "candidate = list('levez vous svp pour cette minute de silence')\n",
        "print('with smoothing score', sentence_bleu([r1], candidate, smoothing_function=chencherry.method1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnuAvbdVhNwB",
        "outputId": "69c1fbc6-a04b-49f0-ac83-50284989b3cf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with smoothing score 0.6194291765462159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trax에 의한 번역"
      ],
      "metadata": {
        "id": "Bhw4hYIgpTyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trax 설치하기\n",
        "!pip install -q -U trax"
      ],
      "metadata": {
        "id": "tzQgiPWghaqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82bd908-497f-450a-aa31-771fd21c16fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.9/637.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KnZUnHzVVPzS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1B5GJ5_6XvW94q1GLjsb4stW9jdh-POwn",
      "authorship_tag": "ABX9TyPN3J/Ge8ZXHJrOT2xA3nps",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}